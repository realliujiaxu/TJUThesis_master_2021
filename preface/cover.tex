% % !Mode:: "TeX:UTF-8"

% %%  可通过增加或减少 setup/format.tex中的
% %%  第274行 \setlength{\@title@width}{8cm}中 8cm 这个参数来 控制封面中下划线的长度。

% \cheading{天津大学~2016~届本科生毕业论文}      % 设置正文的页眉，需要填上对应的毕业年份
% \ctitle{基于顾客有限理性预期的定价与供应链结构}    % 封面用论文标题，自己可手动断行
% \caffil{管理与经济学部} % 学院名称
% \csubject{工业工程}   % 专业名称
% \cgrade{2012~级}            % 年级
% \cauthor{秦昱博}            % 学生姓名
% \cnumber{3012209017}        % 学生学号
% \csupervisor{杨道箭}        % 导师姓名
% \crank{副教授}              % 导师职称

% \cdate{\the\year~年~\the\month~月~\the\day~日}

% \cabstract{
% 中文摘要一般在~400~字以内，简要介绍毕业论文的研究目的、方法、结果和结论，语言力求精炼。中英文摘要均要有关键词，一般为~3~—~7~个。字体为小四号宋体，各关键词之间要有分号。英文摘要应与中文摘要相对应，字体为小四号~Times New Roman，详见模板。
% }

% \ckeywords{关键词~1；关键词~2；关键词~3；……；关键词~7（关键词总共~3~—~7~个，最后一个关键词后面没有标点符号）}

% \eabstract{
% The upper bound of the number of Chinese characters is 400. The abstract aims at introducing the research purpose, research methods, research results, and research conclusion of graduation thesis, with refining words. Generally speaking, both the Chinese and English abstracts require the keywords, the number of which varies from 3 to 7, with a semicolon between adjacent words. The font of the English Abstract is Times New Roman, with the size of 12pt(small four).
% }

% \ekeywords{keyword 1, keyword 2, keyword 3, ……, keyword 7 (no punctuation at the end)}

% \makecover

% \clearpage


% !Mode:: "TeX:UTF-8"


\ctitle{基于生成式对抗网络的图像编辑与多模态图像转换}  %封面用论文标题，自己可手动断行
\etitle{Generative Adversarial Networks Based Image Editing and Multi Modal Image Translation}
\caffil{天津大学智能与计算学部} %学院名称
\cfirstsubjecttitle{\textbf{专业类别}}
\cfirstsubject{计算机技术}   %专业
\csubjecttitle{\textbf{研究方向}}
\csubject{计算机视觉}   %专业
\cauthortitle{\textbf{作者姓名}}     % 学位
\cauthor{刘家旭}   %学生姓名
\csupervisortitle{\textbf{指导教师}}
\csupervisor{朱鹏飞~~副教授} %导师姓名
\ccorsupervisortitle{\textbf{企业导师}}
\ccorsupervisor{刘昕} %导师姓名

\teachertable{
\begin{table}[h]
\centering
\song\xiaosi{
\begin{tabularx}{\textwidth}{|*{4}{>{\centering\arraybackslash}X|}}
\hline
\textbf{答辩日期}                & \multicolumn{3}{c|}{2021 年   月   日}       \\ \hline
\textbf{答辩委员会}               & \textbf{姓名} & \textbf{职称} & \textbf{工作单位} \\ \hline
\textbf{主席}                  &             &             &               \\ \hline
\multirow{2}{*}{\textbf{委员}} &             &             &               \\ \cline{2-4} 
                             &             &             &               \\ \hline
\end{tabularx}}
\end{table}}


\declaretitle{独创性声明}
\declarecontent{
本人声明所呈交的学位论文是本人在导师指导下进行的研究工作和取得的研究成果，除了文中特别加以标注和致谢之处外，论文中不包含其他人已经发表或撰写过的研究成果，也不包含为获得 {\underline{\kaiGB{\sihao{\textbf{~~天津大学~~}}}}} 或其他教育机构的学位或证书而使用过的材料。与我一同工作的同志对本研究所做的任何贡献均已在论文中作了明确的说明并表示了谢意。
}
\authorizationtitle{学位论文版权使用授权书}
\authorizationcontent{
本学位论文作者完全了解{\underline{\kaiGB{\sihao{\textbf{~~天津大学~~}}}}}有关保留、使用学位论文的规定。特授权{\underline{\kaiGB{\sihao{\textbf{~~天津大学~~}}}}} 可以将学位论文的全部或部分内容编入有关数据库进行检索，并采用影印、缩印或扫描等复制手段保存、汇编以供查阅和借阅。同意学校向国家有关部门或机构送交论文的复印件和磁盘。
}
\authorizationadd{(保密的学位论文在解密后适用本授权说明)}
\authorsigncap{学位论文作者签名:}
\supervisorsigncap{导师签名:}
\signdatecap{签字日期:}


\cdate{\CJKdigits{\the\year} 年\CJKnumber{\the\month} 月 \CJKnumber{\the\day} 日}
% 如需改成二零一二年四月二十五日的格式，可以直接输入，即如下所示
\cdate{二零二一年十月}
% \cdate{\the\year 年\the\month 月 \the\day 日} % 此日期显示格式为阿拉伯数字 如2012年4月25日
\cabstract{

生成式对抗网络目前广泛用于图像编辑、图像变换等领域。

在图像编辑方面，生成式对抗网络 (GAN) 可以生成具有不同属性的逼真图像。最近的研究表明，在预训练模型的隐空间中进行特定的向量运算，我们可以人为控制生成图像的属性变化。现有的方法是通过在隐空间搜索相应的语义方向来实现这一点，但由于生成模型是在没有属性标签监督的情况下训练的，因此这些方法得到的结果往往存在语义耦合。为了解决这一问题，并更准确地控制生成图像的属性，我们提出了属性一致生成对抗网络(Attribute Consistent Generative Adversarial Networks)，简称ACGAN。这是一种基于属性训练的，同时可控语义方向被投影到正交空间的生成模型。具体来说，我们首先设计了一种属性量化方法来获得连续标签。然后在连续标签上训练属性回归器，用于在GAN训练阶段约束输入属性变量和生成结果属性之间的一致性。我们将隐变量分解为内容变量和属性变量。属性变量位于正交空间中，从而在理论上保证属性之间的解耦。

在图像变换方面，如今从临床诊断到公共安全，许多实际场景都需要多模态图像。生成式对抗网络刚刚被应用到多模态图像转换，就展现出了惊人的性能，但由于难以对多个输入之间的相关性进行建模，因此多模态图像翻译仍然具有挑战性。在本文中，我们提出了一种联合注意力生成式对抗网络 (Joint Attetion Generative Adversarial Networks, JAGAN) 框架，通过可用的多模态图像生成缺失的模态图像。为了更有效地提取所需模态对应的多模态表示，我们使用自表示网络来驱动注意力模块。提取出的多模态特征可以与目标模态保持通道级的一致性，极大地提高了多模态图像变换性能。

}

\ckeywords{生成式对抗网络，图像生成，多模态图像变换，语义耦合}

\eabstract{

Generative Adversarial Networks (GANs) are currently widely used in image editing, image translation and other fields.

Recent research suggests that Generative Adversarial Networks can produce realistic images with different attributes. To precisely control each attribute of generated images, current methods search the semantic directions in the latent space of a pretrained model. Since the generative models are trained without the supervision of attribute labels, these methods yield semantic entanglement. To tackle these concerns, we propose Attribute Consistent Generative Adversarial Nets, termed ACGAN, to train an attribute-based generative model while projecting the controllable semantic directions to an orthogonal space. Specifically, we first design an attribute quantification method to obtain the continuous labels. An attribute regressor trained by them is applied to constrain the attribute consistency between the input attribute code and the generated results. We decompose the latent code into the content code and the attribute code. The attribute code lies in an orthogonal space, so as to theoretically ensure disentanglement between attributes.

Multimodal images are required in many practical scenarios, ranging from clinical diagnosis to public security. Data missing often leads to decision bias. Although image translation achieved great progress, multimodal image translation is still challenging due to the difficulty in modeling correlations between multiple inputs. In this paper, we novelly proposed a joint attention GAN (MA-GAN) framework to generate the missing image modality through multimodal available images. To effectively extract the multimodal representation specific to desired modality, we use a self-representation network to drive a inter-modal attention module. The extracted multimodal features can maintain kernel-level consistency with the target modality, which greatly improved the image translation performance.

}

\ekeywords{Generative Adversarial Networks, Image Generation, Multi-Modal Image Translation, Semantic Entanglement}

\makecover
\clearpage