\chapter{总结与展望}

\section{全文总结}

生成式对抗网络自提出以来就一直是深度学习乃至人工智能领域的热门话题。在近几年研究人员的持续努力之下，GANs在训练稳定性、生成图像的质量方面取得了长足的进步。随着GANs生成图像真实度越来越接近真实图像，研究人员开始探索GANs的具体应用。本文就图像编辑和多模态图像转换展开了讨论，指出目前所存在的问题，并给出了相应的解决方案。

我们在第三章讨论了生成式对抗网络在图像编辑方面的应用。研究表明，通过在预训练GANs的隐空间中特定的向量运算，我们可以人为控制生成图像的属性变化，如在人脸合成中我们可以控制人脸的年龄。现有的方法是通过在隐空间搜索相应的语义方向来实现这一点，但由于生成模型是在没有属性标签监督的情况下训练的，因此这些方法得到的结果往往存在语义耦合。为了解决这一问题，并更准确地控制生成图像的属性，我们提出了属性一致生成对抗网络(Attribute Consistent Generative Adversarial Networks)，简称ACGAN。我们的贡献如下：
\begin{enumerate}
    \item 我们将属性映射到预定义的正交空间。每个基向量在正交属性空间中的坐标表示属性强度。
    \item 在训练阶段约束生成图像的预测属性值与输入属性变量一致，有效将可控语义方向投影到正交属性空间。
    \item 为了将我们的方法应用于更常见的二值属性数据集，我们计了一种属性量化策略来获得连续属性伪标签，可以灵活地与许多现有方法集成以提高编辑性能。
    \item 统一了GAN的训练与属性控制，在隐空间和生成模型中全面优化属性可控方向。
\end{enumerate}

我们在第三章讨论了生成式对抗网络在多模态图像转换方面的应用。从临床诊断到公共安全，许多实际场景都需要多模态图像。生成式对抗网络刚刚被应用到多模态图像转换，就展现出了惊人的性能，但由于难以对多个输入之间的相关性进行建模，因此多模态图像翻译仍然具有挑战性。在本文中，我们提出了一种联合注意力生成式对抗网络 (Joint Attetion Generative Adversarial Networks, JAGAN) 框架，通过可用的多模态图像生成缺失的模态图像。我们的贡献如下：
\begin{enumerate}
    \item 我们提出模态间注意力，用于模态间互补性用输入模态的信息补充生成目标模态所需要的信息。
    \item 我们引入自表示网络来指导训练期间的生成模型，这提供了模态补充模块所需的特征兼容性，并在特征提取阶段过滤掉无关信息。
    \item 通过与现有方法在多模态图像转换任务的定量和定性比较，证明了我们方法的能够生成更精确和逼真的结果。
\end{enumerate}

\section{展望}

虽然我们提出的 ACGAN 与其他最先进的技术相比实现了卓越的性能，但仍存在一些局限性。例如，灰头发和白皮肤具有相似的颜色，这可能导致这些属性难以解耦。 此外，对真实图像的编辑十分依赖GAN逆映射（GAN inversion）的结果，这通常需要复杂的 GAN 架构。 我们使用过的 StyleGAN2-mini 仍然需要大量的时间。 未来，我们将探索更高效的回归器和 GAN 架构。

我们提出的 JAGAN 同样存在类似的问题：JAGAN与其他最先进的技术相比实现了卓越的性能，但需要更多的计算资源和计算时间。 未来，我们将探索更高效的网络架构。